{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45587fec-4a1a-4412-aff0-3f12512366fe",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "929601af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec005a7-bcc3-430c-8052-f32e65fb52fb",
   "metadata": {},
   "source": [
    "# User-Item Interaction Preparation\n",
    "\n",
    "## Objective\n",
    "Prepare a user-item interaction matrix for recommendation system training by:\n",
    "1. Filtering active users\n",
    "2. Creating dense indices for users/items\n",
    "3. Extracting core rating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79779182",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"C:/Users/anees/Desktop/datasets/unified_dataset\"\n",
    "df = (\n",
    "    pl.scan_parquet(DATASET).select([\"user_id\", \"asin\", \"rating\"])\n",
    "      .filter(pl.len().over(\"user_id\") >= 5)\n",
    "      .with_columns([\n",
    "          pl.col(\"user_id\").rank(\"dense\").cast(pl.Int32).alias(\"user_idx\"),\n",
    "          pl.col(\"asin\").rank(\"dense\").cast(pl.Int32).alias(\"item_idx\"),\n",
    "      ])\n",
    "      .select([\"user_idx\",\"item_idx\",\"rating\"])\n",
    "      .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88116882-6d53-4768-a60d-1bf89de2a55c",
   "metadata": {},
   "source": [
    "### Data Preparation for User Recommendation System\n",
    "\n",
    "The following steps prepare the user-item ratings data for building a recommendation system:\n",
    "\n",
    "1. **Convert Columns to NumPy Arrays**  \n",
    "   The user_idx, item_idx, and rating columns are extracted from the DataFrame and converted to NumPy arrays for efficient computation\n",
    "2. **Determine Matrix Shape**\n",
    "    Calculate the total number of unique users and items to define the shape of the user-item interaction matrix\n",
    "3. **Train-Test Split**\n",
    "    Split the dataset into training and testing sets using index-based selection to preserve correspondence between users, items, and ratings\n",
    "4. Extract the corresponding user, item, and rating values for both training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8295b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to numpy arrays\n",
    "user_idx = df[\"user_idx\"].to_numpy()\n",
    "item_idx = df[\"item_idx\"].to_numpy()\n",
    "ratings = df[\"rating\"].cast(pl.Float32).to_numpy()\n",
    "\n",
    "# Determine matrix shape\n",
    "num_users = user_idx.max() + 1\n",
    "num_items = item_idx.max() + 1\n",
    "\n",
    "# Train-test split on indices\n",
    "indices = np.arange(len(df))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "train_user_idx = user_idx[train_indices]\n",
    "train_item_idx = item_idx[train_indices]\n",
    "train_ratings = ratings[train_indices]\n",
    "\n",
    "test_user_idx = user_idx[test_indices]\n",
    "test_item_idx = item_idx[test_indices]\n",
    "test_ratings = ratings[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a7462-dae6-4c10-a45f-25524853ee20",
   "metadata": {},
   "source": [
    "### Building the Recommendation Model\n",
    "\n",
    "1. **Create Sparse User-Item Matrix**\n",
    "Construct a sparse matrix using the training data, where rows represent users, columns represent items, and values represent ratings. The matrix is converted to CSR format for efficient access\n",
    "2. **Train ALS Model**\n",
    "Initialize and train an Alternating Least Squares (ALS) model on the training matrix. ALS is a matrix factorization algorithm commonly used for collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8b0af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: Intel MKL BLAS is configured to use 6 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'MKL_NUM_THREADS=1' or by callng 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having MKL use a threadpool can lead to severe performance issues\n",
      "  check_blas_config()\n"
     ]
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()\n",
    "\n",
    "# Create sparse matrix\n",
    "train_matrix = coo_matrix((train_ratings, (train_user_idx, train_item_idx)), shape=(num_users, num_items)).tocsr()\n",
    "\n",
    "# Train ALS model\n",
    "model = AlternatingLeastSquares(\n",
    "    factors=50,\n",
    "    regularization=0.01,\n",
    "    iterations=15,\n",
    "    use_gpu=False,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(train_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34531d0c-b5fd-4db0-9e3c-0577067db52e",
   "metadata": {},
   "source": [
    "### Model Evaluation on Test Set\n",
    "\n",
    "1. **Generate Predictions**  \n",
    "   Loop through the test set and compute predicted ratings using the dot product of user and item latent factors, but only if both the user and item exist in the model\n",
    "2. **Compute RMSE**\n",
    "Evaluate model performance using Root Mean Squared Error (RMSE), which measures the average deviation between predicted and actual ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fd53a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE on test set: 4.5054\n"
     ]
    }
   ],
   "source": [
    "preds, actuals = [], []\n",
    "for u, i, r in zip(test_user_idx, test_item_idx, test_ratings):\n",
    "    if u < model.user_factors.shape[0] and i < model.item_factors.shape[0]:\n",
    "        pred = model.user_factors[u] @ model.item_factors[i]\n",
    "        preds.append(pred)\n",
    "        actuals.append(r)\n",
    "\n",
    "rmse = root_mean_squared_error(actuals, preds)\n",
    "print(f\" RMSE on test set: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b400b795-c1ad-4d2b-a1cf-f6ed3223f994",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "* The RSME was found to be 4.5\n",
    "* This means the average distance between the perdicted score and actual score is almost as large as the entire scale\n",
    "* This indicates poor model perfromace\n",
    "* Model is not capturing patterns well, perhaps due to:\n",
    "    - Sparse data\n",
    "    - Inadequate feature learning (too few factors or iterations)\n",
    "    - Not enough regularization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
